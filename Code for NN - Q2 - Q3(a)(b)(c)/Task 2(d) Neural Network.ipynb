{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deb7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import initializers\n",
    "import math \n",
    "from tensorflow import keras\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519ad55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Yingxing Huang/Desktop/Compsci 361 Machine Learning/A3 Group Project/Data/A3\")\n",
    "\n",
    "train_data = pd.read_csv (\"train.csv\")\n",
    "test_data = pd.read_csv (\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10410e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4700366b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d619f7b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42d0a8",
   "metadata": {},
   "source": [
    "## Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802d301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two train set and test set\n",
    "full_data = pd.concat([train_data, test_data], axis=0)\n",
    "#full_data\n",
    "text = full_data['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2389b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector shape: (534, 14927) \n",
      "\n",
      "article vector\n",
      " [[0.         0.02025329 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.02656619 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency - Inverse Document Frequency (TF - IDF)\n",
    "vectorizor = TfidfVectorizer() \n",
    "vectorizor.fit (text)\n",
    "\n",
    "# encode article \n",
    "vector = vectorizor.transform(text)\n",
    "\n",
    "# print encoded vector\n",
    "print (f'vector shape: {vector.shape} \\n')\n",
    "print (f'article vector\\n {vector.toarray()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b3e1e",
   "metadata": {},
   "source": [
    "## Preparing data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd08c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X = vector[:428].toarray()\n",
    "test_X = vector[428:].toarray()\n",
    "train_y_bool = list(train_data ['Category'] == \"tech\")\n",
    "test_y_bool = list(test_data ['Category'] == \"tech\")\n",
    "train_y = np.array(list(map(int, train_y_bool)))\n",
    "test_y =  np.array(list(map(int, test_y_bool)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430d3d9",
   "metadata": {},
   "source": [
    "# Task 2(d) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704b188",
   "metadata": {},
   "source": [
    "## Train a neural network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d4ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4439\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4860\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5327\n"
     ]
    }
   ],
   "source": [
    "# define the neural network \n",
    "hidden_units = [5, 20, 40]\n",
    "n_features = train_X.shape[1]\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "losses = {}\n",
    "for h in hidden_units:\n",
    "    build_NN (h, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ed69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN (h, train_X, train_y, test_X, test_y):\n",
    "    initializer = initializers.RandomUniform(minval = 0, maxval = 0.1, seed=None)\n",
    "    nn_model = Sequential ()\n",
    "    nn_model.add (Dense(h, input_dim = n_features, activation = 'relu', kernel_initializer = initializer) )  # hidden layer: a dense layer that is fully connected\n",
    "    nn_model.add(Dense(2, activation = 'softmax', kernel_initializer = initializer))   # ouput layer\n",
    "    \n",
    "    # define optimiser and initialise weights \n",
    "    opt = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "    # compile the model\n",
    "    nn_model.compile (loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "    # fit the model\n",
    "    history = nn_model.fit (train_X, train_y, epochs = 100 , batch_size = 10, verbose = 0)\n",
    "    losses[h] = history.history['loss']    # keep track of the loss\n",
    "    \n",
    "    # train accuracy\n",
    "    _, accuracy = nn_model.evaluate(train_X, train_y)\n",
    "    train_accuracy.append (accuracy)\n",
    "\n",
    "    # test accuracy\n",
    "    y_pred = nn_model.predict_classes(test_X)\n",
    "    test_accuracy.append(accuracy_score (test_y, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_losses = []\n",
    "for i in losses.keys():\n",
    "    avg_losses.append(statistics.mean(losses[i]))\n",
    "avg_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fa73b",
   "metadata": {},
   "source": [
    "## Plot Cross-Entropy Loss vs Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124c4e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set the width and height of the graph\n",
    "f = plt.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(8)\n",
    "\n",
    "x = list(range(1,101))\n",
    "for j in losses.keys():\n",
    "    y = losses[j]\n",
    "    l = \"{} hidden units\".format (j)\n",
    "    plt.plot(x, y, label = l)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.title (\"The Impact of the Number of Hidden Units on the average of cross-entropy loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc08d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A zoomed-in version \"\"\"\n",
    "# set the width and height of the graph\n",
    "f = plt.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(8)\n",
    "\n",
    "x = list(range(1,101))\n",
    "for j in losses.keys():\n",
    "    y = losses[j]\n",
    "    l = \"{} hidden units\".format (j)\n",
    "    plt.plot(x, y, label = l)\n",
    "    plt.xlim(5, 100)\n",
    "    plt.ylim(0.69314, 0.69325)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.title (\"The Impact of the Number of Hidden Units on the average of cross-entropy loss\\n     Zoomed-in tail \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A zoomed-in version \"\"\"\n",
    "# set the width and height of the graph\n",
    "f = plt.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(8)\n",
    "\n",
    "x = list(range(1,101))\n",
    "for j in losses.keys():\n",
    "    y = losses[j]\n",
    "    l = \"{} hidden units\".format (j)\n",
    "    plt.plot(x, y, label = l)\n",
    "    plt.xlim(0, 6)\n",
    "    plt.ylim(0.69314, 0.69375)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.title (\"The Impact of the Number of Hidden Units on the average of cross-entropy loss\\n     Zoomed-in head \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ac864",
   "metadata": {},
   "source": [
    "### The Effect of the Numbers of Hidden Units\n",
    "\n",
    "A higher number of hidden units in the hidden layer seems to have a greater impact on reducing the average entropy loss after the fist iteration. After that, the loss incurred by different numbers of hidden units converge at the third iteration. Till around the 46th iteration, the number of hidden units have little influence on the amount of loss. However, there is a surge of cross-entropy loss between the 46th and 61st iterations when 40 hidden units are deployed. Subsequently, there is a minor surge of loss between the 75th and the 18th itertions when 20 hidden units are used, followed by a tiny surge when 5 hidden units are used. Therefore, it appears that neural network with less hidden units tend to be more stable with respect to average cross-entropy loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cefff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad8771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
